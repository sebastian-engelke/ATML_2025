{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Jwv4NQIZQx3"
   },
   "source": [
    "# NLP Seminar 2: Normalization and Simple Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first NLP seminar, we focus on classical text normalization methods (stemming, lemmatization) and simple word embedding/vectorization techniques (bag of words, TF-IDF), that will allow us to train machine learning methods on text data. \n",
    "\n",
    "We use the `nltk` (natural language toolkit) python package, as well as the machine learning framework `scikit-learn`.\n",
    "If you want to learn more about the popular `nltk` module, refer to the [official website](https://www.nltk.org/) ([API reference](https://www.nltk.org/api/nltk.html), [installation guide](https://www.nltk.org/install.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1946,
     "status": "ok",
     "timestamp": 1662019861618,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "ZSzIHTvFUnOn"
   },
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 999,
     "status": "ok",
     "timestamp": 1662019862614,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "-AtJGJBCWZpo",
    "outputId": "1f533aca-94fc-4526-b7f7-18af2bbce299"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First download some nltk resources\n",
    "# (By default '!pip install nltk' does not actually download every resource in the module,\n",
    "# as for example some language models are heavy.)\n",
    "# The following commands should download every resource needed for this practical:\n",
    "nltk.download('popular', quiet=True)\n",
    "nltk.download('universal_tagset', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8pxK9ucU-LX"
   },
   "source": [
    "# 1. Download the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the famous `20newsgroups` dataset. It consists of a large collection of news posts across 20 topics. We will be using it to test some basic NLP techniques and train a multi-class classification model to predict the most likely topic for unseen news posts. \n",
    "For more information, check [the dataset description](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset) and the [import function helper](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html)\n",
    "\n",
    "To make the task a bit harder, we import the data without the headers, footers and quotes.\n",
    "\n",
    "We also restrict the dataset to only 4 of the categories, for presentation simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 19957,
     "status": "ok",
     "timestamp": 1662019882569,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "VBE9MVJDTSHK"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# we restrict the data to the following response categories:\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "data_train = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42,\n",
    "                                remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "\n",
    "data_test = fetch_20newsgroups(subset=\"test\", categories=categories, shuffle=True, random_state=42,\n",
    "                               remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "\n",
    "df_train = pd.DataFrame({\"text\": data_train.data, \"class\": data_train.target})\n",
    "df_test = pd.DataFrame({\"text\": data_test.data, \"class\": data_test.target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1662019882569,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "yaOYzXrqUmTY",
    "outputId": "10c2ff36-5713-4bef-ca6d-afec8797c10a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does anyone know of a good way (standard PC ap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi,\\n\\n\\tI have a problem, I hope some of the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Well, I'll email also, but this may apply to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello,\\n\\nI'm writing a paper on the role of t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  Does anyone know of a good way (standard PC ap...      1\n",
       "1  Hi,\\n\\n\\tI have a problem, I hope some of the ...      1\n",
       "2  (Well, I'll email also, but this may apply to ...      3\n",
       "3  Hello,\\n\\nI'm writing a paper on the role of t...      3\n",
       "4                                                         3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1662019882569,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "Gq_er6VLuSTE",
    "outputId": "0698f796-4d3f-4fcd-ec8a-6d4c3d4c10fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many classes are there to identify?\n",
    "df_train[\"class\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1662019882569,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "fPPcy8rpuYmF",
    "outputId": "e5cf7ee6-cf81-4849-80e5-5f581d05af79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "# What do these class labels correspond to?\n",
    "target_names = data_train.target_names\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1662019882569,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "Ck87gAPDWv-f",
    "outputId": "cf91124d-94d3-46e5-800f-a8cf2df37b31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2257, 2)\n",
      "Test: (1502, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {df_train.shape}\")\n",
    "print(f\"Test: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1uc0__Px0R5"
   },
   "source": [
    "# 2. Natural Language Processing: Text Normalization\n",
    "\n",
    "For classic NLP techniques, text normalization can be crucial to good model performance. Their main aim is to decrease the vocabulary size, by reducing similar words to common roots or removing useless words. These techniques include word tokenization, stopword removal, lemmatization, and more. We'll try a few of those here to see their impact on our news classification model.\n",
    "\n",
    "We begin by testing those text normalization methods on a single news post example, before applying them to the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1662019882569,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "NWWF9t3S0OZo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi:\n",
      "\n",
      "I am digitizing a NTSC signal and displaying on a PC video monitor.\n",
      "It is known that the display response of tubes is non-linear and is\n",
      "sometimes said to follow Gamma-Law. I am not certain if these\n",
      "non-linearities are \"Gamma-corrected\" before encoding NTSC signals\n",
      "or if the TV display is supposed to correct this.\n",
      " \n",
      "Also, if  256 grey levels, for example, are coded in a C program do\n",
      "these intensity levels appear with linear brightness on a PC\n",
      "monitor? In other words does PC monitor display circuitry\n",
      "correct for \"gamma errrors\"?\n",
      " \n",
      "Your response is much appreciated.\n",
      " \n",
      "Amjad.\n"
     ]
    }
   ],
   "source": [
    "# Take an example entry in the training set for demonstration purposes here\n",
    "text = df_train[\"text\"].iloc[11]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yv7hitczyvUA"
   },
   "source": [
    "### 2.1. Tokenization\n",
    "Before any type of normalization, the first step is to tokenize each document in our corpus. We again rely on the NLTK tokenizer to convert a string to a list of words. We here tokenize the selected `text` observation from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1662019882570,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "pfbCYh3Jyu5z",
    "outputId": "b7c341ad-f608-4335-9d3b-c5de97c12b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', ':', 'I', 'am', 'digitizing', 'a', 'NTSC', 'signal', 'and', 'displaying', 'on', 'a', 'PC', 'video', 'monitor', '.', 'It', 'is', 'known', 'that', 'the', 'display', 'response', 'of', 'tubes', 'is', 'non-linear', 'and', 'is', 'sometimes', 'said', 'to', 'follow', 'Gamma-Law', '.', 'I', 'am', 'not', 'certain', 'if', 'these', 'non-linearities', 'are', '``', 'Gamma-corrected', \"''\", 'before', 'encoding', 'NTSC', 'signals', 'or', 'if', 'the', 'TV', 'display', 'is', 'supposed', 'to', 'correct', 'this', '.', 'Also', ',', 'if', '256', 'grey', 'levels', ',', 'for', 'example', ',', 'are', 'coded', 'in', 'a', 'C', 'program', 'do', 'these', 'intensity', 'levels', 'appear', 'with', 'linear', 'brightness', 'on', 'a', 'PC', 'monitor', '?', 'In', 'other', 'words', 'does', 'PC', 'monitor', 'display', 'circuitry', 'correct', 'for', '``', 'gamma', 'errrors', \"''\", '?', 'Your', 'response', 'is', 'much', 'appreciated', '.', 'Amjad', '.']\n"
     ]
    }
   ],
   "source": [
    "text_tokens = nltk.word_tokenize(text)\n",
    "print(text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfzsMmdIymLR"
   },
   "source": [
    "### 2.2. Stopwords and punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5umdlOizLCp"
   },
   "source": [
    "Stopwords correspond to unimportant words which might safely be ignored for the task at hand. For the specific task of news classification, we might for example rely on the default stopwords provided by NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1662019882923,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "QFikvQzWUkq7",
    "outputId": "186cfccc-ddf4-4e77-e5d5-7a98d90eb80e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "# Let's use the nltk stopwords available for the English language\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might also want to remove punctuation tokens. Here is a list of standard punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to reducing similar words to common roots, stemming is the simplest and fastest approach. Stemming is an abstract rule-based process that stems or removes some of the last few characters from a word. This sometimes leads to incorrect meanings and spelling, as a downsize.\n",
    "\n",
    "Let's try two different stemmers: \"PorterStemmer\" and the slightly more recent \"SnowballStemmer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', ':', 'i', 'am', 'digit', 'a', 'ntsc', 'signal', 'and', 'display', 'on', 'a', 'pc', 'video', 'monitor', '.', 'it', 'is', 'known', 'that', 'the', 'display', 'respons', 'of', 'tube', 'is', 'non-linear', 'and', 'is', 'sometim', 'said', 'to', 'follow', 'gamma-law', '.', 'i', 'am', 'not', 'certain', 'if', 'these', 'non-linear', 'are', '``', 'gamma-correct', \"''\", 'befor', 'encod', 'ntsc', 'signal', 'or', 'if', 'the', 'tv', 'display', 'is', 'suppos', 'to', 'correct', 'thi', '.', 'also', ',', 'if', '256', 'grey', 'level', ',', 'for', 'exampl', ',', 'are', 'code', 'in', 'a', 'c', 'program', 'do', 'these', 'intens', 'level', 'appear', 'with', 'linear', 'bright', 'on', 'a', 'pc', 'monitor', '?', 'in', 'other', 'word', 'doe', 'pc', 'monitor', 'display', 'circuitri', 'correct', 'for', '``', 'gamma', 'errror', \"''\", '?', 'your', 'respons', 'is', 'much', 'appreci', '.', 'amjad', '.']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "text_stems = [ps.stem(word) for word in text_tokens]\n",
    "print(text_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m ps.stem(word, to_lowercase=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mDocstring:\u001b[39m :param to_lowercase: if `to_lowercase=True` the word always lowercase\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\pascheo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\nltk\\stem\\porter.py\n",
      "\u001b[31mType:\u001b[39m      method"
     ]
    }
   ],
   "source": [
    "ps.stem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi  =>  hi\n",
      ":  =>  :\n",
      "I  =>  i\n",
      "am  =>  am\n",
      "digitizing  =>  digit\n",
      "a  =>  a\n",
      "NTSC  =>  ntsc\n",
      "signal  =>  signal\n",
      "and  =>  and\n",
      "displaying  =>  display\n",
      "on  =>  on\n",
      "a  =>  a\n",
      "PC  =>  pc\n",
      "video  =>  video\n",
      "monitor  =>  monitor\n",
      ".  =>  .\n",
      "It  =>  it\n",
      "is  =>  is\n",
      "known  =>  known\n",
      "that  =>  that\n",
      "the  =>  the\n",
      "display  =>  display\n",
      "response  =>  respons\n",
      "of  =>  of\n",
      "tubes  =>  tube\n",
      "is  =>  is\n",
      "non-linear  =>  non-linear\n",
      "and  =>  and\n",
      "is  =>  is\n",
      "sometimes  =>  sometim\n",
      "said  =>  said\n",
      "to  =>  to\n",
      "follow  =>  follow\n",
      "Gamma-Law  =>  gamma-law\n",
      ".  =>  .\n",
      "I  =>  i\n",
      "am  =>  am\n",
      "not  =>  not\n",
      "certain  =>  certain\n",
      "if  =>  if\n",
      "these  =>  these\n",
      "non-linearities  =>  non-linear\n",
      "are  =>  are\n",
      "``  =>  ``\n",
      "Gamma-corrected  =>  gamma-correct\n",
      "''  =>  ''\n",
      "before  =>  befor\n",
      "encoding  =>  encod\n",
      "NTSC  =>  ntsc\n",
      "signals  =>  signal\n",
      "or  =>  or\n",
      "if  =>  if\n",
      "the  =>  the\n",
      "TV  =>  tv\n",
      "display  =>  display\n",
      "is  =>  is\n",
      "supposed  =>  suppos\n",
      "to  =>  to\n",
      "correct  =>  correct\n",
      "this  =>  thi\n",
      ".  =>  .\n",
      "Also  =>  also\n",
      ",  =>  ,\n",
      "if  =>  if\n",
      "256  =>  256\n",
      "grey  =>  grey\n",
      "levels  =>  level\n",
      ",  =>  ,\n",
      "for  =>  for\n",
      "example  =>  exampl\n",
      ",  =>  ,\n",
      "are  =>  are\n",
      "coded  =>  code\n",
      "in  =>  in\n",
      "a  =>  a\n",
      "C  =>  c\n",
      "program  =>  program\n",
      "do  =>  do\n",
      "these  =>  these\n",
      "intensity  =>  intens\n",
      "levels  =>  level\n",
      "appear  =>  appear\n",
      "with  =>  with\n",
      "linear  =>  linear\n",
      "brightness  =>  bright\n",
      "on  =>  on\n",
      "a  =>  a\n",
      "PC  =>  pc\n",
      "monitor  =>  monitor\n",
      "?  =>  ?\n",
      "In  =>  in\n",
      "other  =>  other\n",
      "words  =>  word\n",
      "does  =>  doe\n",
      "PC  =>  pc\n",
      "monitor  =>  monitor\n",
      "display  =>  display\n",
      "circuitry  =>  circuitri\n",
      "correct  =>  correct\n",
      "for  =>  for\n",
      "``  =>  ``\n",
      "gamma  =>  gamma\n",
      "errrors  =>  errror\n",
      "''  =>  ''\n",
      "?  =>  ?\n",
      "Your  =>  your\n",
      "response  =>  respons\n",
      "is  =>  is\n",
      "much  =>  much\n",
      "appreciated  =>  appreci\n",
      ".  =>  .\n",
      "Amjad  =>  amjad\n",
      ".  =>  .\n"
     ]
    }
   ],
   "source": [
    "for w, s in zip(text_tokens, text_stems):\n",
    "    print(w, ' => ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', ':', 'i', 'am', 'digit', 'a', 'ntsc', 'signal', 'and', 'display', 'on', 'a', 'pc', 'video', 'monitor', '.', 'it', 'is', 'known', 'that', 'the', 'display', 'respons', 'of', 'tube', 'is', 'non-linear', 'and', 'is', 'sometim', 'said', 'to', 'follow', 'gamma-law', '.', 'i', 'am', 'not', 'certain', 'if', 'these', 'non-linear', 'are', '``', 'gamma-correct', \"''\", 'befor', 'encod', 'ntsc', 'signal', 'or', 'if', 'the', 'tv', 'display', 'is', 'suppos', 'to', 'correct', 'this', '.', 'also', ',', 'if', '256', 'grey', 'level', ',', 'for', 'exampl', ',', 'are', 'code', 'in', 'a', 'c', 'program', 'do', 'these', 'intens', 'level', 'appear', 'with', 'linear', 'bright', 'on', 'a', 'pc', 'monitor', '?', 'in', 'other', 'word', 'doe', 'pc', 'monitor', 'display', 'circuitri', 'correct', 'for', '``', 'gamma', 'errror', \"''\", '?', 'your', 'respons', 'is', 'much', 'appreci', '.', 'amjad', '.']\n"
     ]
    }
   ],
   "source": [
    "snowstem = SnowballStemmer(\"english\")\n",
    "text_sstems = [snowstem.stem(word) for word in text_tokens]\n",
    "print(text_sstems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thi', 'this')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(a,b) for a, b in zip(text_stems, text_sstems) if a!=b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJnX396HzwRM"
   },
   "source": [
    "### 2.4. Part-of-speech (POS) tagging\n",
    "Part-of-speech tagging categorizes words as a particular part-of-speech (e.g. verb, noun, etc ...) using the word itself and the surrounding context in a predictive model. Those tags can be useful for several types of analyses. In particular, they are used for lemmatization.\n",
    "\n",
    "Different more or less precise tagsets exist for each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1662019882923,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "EnbOxzaCzvtw",
    "outputId": "33bd40b9-cfe3-461a-cf2d-7db45c8b48a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi', 'NN'), (':', ':'), ('I', 'PRP'), ('am', 'VBP'), ('digitizing', 'VBG'), ('a', 'DT'), ('NTSC', 'NNP'), ('signal', 'NN'), ('and', 'CC'), ('displaying', 'VBG'), ('on', 'IN'), ('a', 'DT'), ('PC', 'NN'), ('video', 'NN'), ('monitor', 'NN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('known', 'VBN'), ('that', 'IN'), ('the', 'DT'), ('display', 'NN'), ('response', 'NN'), ('of', 'IN'), ('tubes', 'NNS'), ('is', 'VBZ'), ('non-linear', 'JJ'), ('and', 'CC'), ('is', 'VBZ'), ('sometimes', 'RB'), ('said', 'VBD'), ('to', 'TO'), ('follow', 'VB'), ('Gamma-Law', 'NNP'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('not', 'RB'), ('certain', 'JJ'), ('if', 'IN'), ('these', 'DT'), ('non-linearities', 'NNS'), ('are', 'VBP'), ('``', '``'), ('Gamma-corrected', 'JJ'), (\"''\", \"''\"), ('before', 'IN'), ('encoding', 'VBG'), ('NTSC', 'NNP'), ('signals', 'NNS'), ('or', 'CC'), ('if', 'IN'), ('the', 'DT'), ('TV', 'NN'), ('display', 'NN'), ('is', 'VBZ'), ('supposed', 'VBN'), ('to', 'TO'), ('correct', 'VB'), ('this', 'DT'), ('.', '.'), ('Also', 'RB'), (',', ','), ('if', 'IN'), ('256', 'CD'), ('grey', 'NN'), ('levels', 'NNS'), (',', ','), ('for', 'IN'), ('example', 'NN'), (',', ','), ('are', 'VBP'), ('coded', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('C', 'NNP'), ('program', 'NN'), ('do', 'VBP'), ('these', 'DT'), ('intensity', 'NN'), ('levels', 'NNS'), ('appear', 'VBP'), ('with', 'IN'), ('linear', 'JJ'), ('brightness', 'NN'), ('on', 'IN'), ('a', 'DT'), ('PC', 'NN'), ('monitor', 'NN'), ('?', '.'), ('In', 'IN'), ('other', 'JJ'), ('words', 'NNS'), ('does', 'VBZ'), ('PC', 'NNP'), ('monitor', 'NN'), ('display', 'NN'), ('circuitry', 'NN'), ('correct', 'NN'), ('for', 'IN'), ('``', '``'), ('gamma', 'JJ'), ('errrors', 'NNS'), (\"''\", \"''\"), ('?', '.'), ('Your', 'PRP$'), ('response', 'NN'), ('is', 'VBZ'), ('much', 'RB'), ('appreciated', 'VBN'), ('.', '.'), ('Amjad', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# We can use the default english pos-tagger provided by NLTK (Penn Treebank)\n",
    "text_PoS_p = nltk.pos_tag(text_tokens)\n",
    "print(text_PoS_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1662019882923,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "EnbOxzaCzvtw",
    "outputId": "33bd40b9-cfe3-461a-cf2d-7db45c8b48a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi', 'NOUN'), (':', '.'), ('I', 'PRON'), ('am', 'VERB'), ('digitizing', 'VERB'), ('a', 'DET'), ('NTSC', 'NOUN'), ('signal', 'NOUN'), ('and', 'CONJ'), ('displaying', 'VERB'), ('on', 'ADP'), ('a', 'DET'), ('PC', 'NOUN'), ('video', 'NOUN'), ('monitor', 'NOUN'), ('.', '.'), ('It', 'PRON'), ('is', 'VERB'), ('known', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('display', 'NOUN'), ('response', 'NOUN'), ('of', 'ADP'), ('tubes', 'NOUN'), ('is', 'VERB'), ('non-linear', 'ADJ'), ('and', 'CONJ'), ('is', 'VERB'), ('sometimes', 'ADV'), ('said', 'VERB'), ('to', 'PRT'), ('follow', 'VERB'), ('Gamma-Law', 'NOUN'), ('.', '.'), ('I', 'PRON'), ('am', 'VERB'), ('not', 'ADV'), ('certain', 'ADJ'), ('if', 'ADP'), ('these', 'DET'), ('non-linearities', 'NOUN'), ('are', 'VERB'), ('``', '.'), ('Gamma-corrected', 'ADJ'), (\"''\", '.'), ('before', 'ADP'), ('encoding', 'VERB'), ('NTSC', 'NOUN'), ('signals', 'NOUN'), ('or', 'CONJ'), ('if', 'ADP'), ('the', 'DET'), ('TV', 'NOUN'), ('display', 'NOUN'), ('is', 'VERB'), ('supposed', 'VERB'), ('to', 'PRT'), ('correct', 'VERB'), ('this', 'DET'), ('.', '.'), ('Also', 'ADV'), (',', '.'), ('if', 'ADP'), ('256', 'NUM'), ('grey', 'NOUN'), ('levels', 'NOUN'), (',', '.'), ('for', 'ADP'), ('example', 'NOUN'), (',', '.'), ('are', 'VERB'), ('coded', 'VERB'), ('in', 'ADP'), ('a', 'DET'), ('C', 'NOUN'), ('program', 'NOUN'), ('do', 'VERB'), ('these', 'DET'), ('intensity', 'NOUN'), ('levels', 'NOUN'), ('appear', 'VERB'), ('with', 'ADP'), ('linear', 'ADJ'), ('brightness', 'NOUN'), ('on', 'ADP'), ('a', 'DET'), ('PC', 'NOUN'), ('monitor', 'NOUN'), ('?', '.'), ('In', 'ADP'), ('other', 'ADJ'), ('words', 'NOUN'), ('does', 'VERB'), ('PC', 'NOUN'), ('monitor', 'NOUN'), ('display', 'NOUN'), ('circuitry', 'NOUN'), ('correct', 'NOUN'), ('for', 'ADP'), ('``', '.'), ('gamma', 'ADJ'), ('errrors', 'NOUN'), (\"''\", '.'), ('?', '.'), ('Your', 'PRON'), ('response', 'NOUN'), ('is', 'VERB'), ('much', 'ADV'), ('appreciated', 'VERB'), ('.', '.'), ('Amjad', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Or the \"universal\" tags\n",
    "text_PoS_u = nltk.pos_tag(text_tokens, tagset=\"universal\")\n",
    "print(text_PoS_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf\n",
    "\n",
    "https://github.com/slavpetrov/universal-pos-tags\n",
    "\n",
    "- VERB - verbs (all tenses and modes)\n",
    "- NOUN - nouns (common and proper)\n",
    "- PRON - pronouns \n",
    "- ADJ - adjectives\n",
    "- ADV - adverbs\n",
    "- ADP - adpositions (prepositions and postpositions)\n",
    "- CONJ - conjunctions\n",
    "- DET - determiners\n",
    "- NUM - cardinal numbers\n",
    "- PRT - particles or other function words\n",
    "- X - other: foreign words, typos, abbreviations\n",
    "- . - punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7byMSxD0yq0O"
   },
   "source": [
    "### 2.5. Lemmatization\n",
    "Lemmatization considers the context and converts the word to its meaningful base form, which is called the \"Lemma\".\n",
    "It uses language-specific lookup tables to find the root forms of words. This makes it more computationnaly expensive than stemming.\n",
    "We here use the `WordNetLemmatizer` (https://www.nltk.org/api/nltk.stem.wordnet.html).\n",
    "It uses the Wordnet database (https://wordnet.princeton.edu/) to find the lemma of a word, given the word AND its PoS tag!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1662019882923,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "P_DEWPixwFcB"
   },
   "outputs": [],
   "source": [
    "# We can use the English language lemmatizer provided by NLTK\n",
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m wnl.lemmatize(word: str, pos: str = \u001b[33m'n'\u001b[39m) -> str\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Lemmatize `word` by picking the shortest of the possible lemmas,\n",
      "using the wordnet corpus reader's built-in _morphy function.\n",
      "Returns the input word unchanged if it cannot be found in WordNet.\n",
      "\n",
      ">>> from nltk.stem import WordNetLemmatizer as wnl\n",
      ">>> print(wnl().lemmatize('dogs'))\n",
      "dog\n",
      ">>> print(wnl().lemmatize('churches'))\n",
      "church\n",
      ">>> print(wnl().lemmatize('aardwolves'))\n",
      "aardwolf\n",
      ">>> print(wnl().lemmatize('abaci'))\n",
      "abacus\n",
      ">>> print(wnl().lemmatize('hardrock'))\n",
      "hardrock\n",
      "\n",
      ":param word: The input word to lemmatize.\n",
      ":type word: str\n",
      ":param pos: The Part Of Speech tag. Valid options are `\"n\"` for nouns,\n",
      "    `\"v\"` for verbs, `\"a\"` for adjectives, `\"r\"` for adverbs and `\"s\"`\n",
      "    for satellite adjectives.\n",
      ":type pos: str\n",
      ":return: The shortest lemma of `word`, for the given `pos`.\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\pascheo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\nltk\\stem\\wordnet.py\n",
      "\u001b[31mType:\u001b[39m      method"
     ]
    }
   ],
   "source": [
    "?wnl.lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1948,
     "status": "ok",
     "timestamp": 1662019884869,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "wCXSxkwIwKvh",
    "outputId": "89c7f2f4-9103-4bf0-823e-b1d5fa3dc41c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi -> Hi\n",
      ": -> :\n",
      "I -> I\n",
      "am -> be\n",
      "digitizing -> digitize\n",
      "a -> a\n",
      "NTSC -> NTSC\n",
      "signal -> signal\n",
      "and -> and\n",
      "displaying -> display\n",
      "on -> on\n",
      "a -> a\n",
      "PC -> PC\n",
      "video -> video\n",
      "monitor -> monitor\n",
      ". -> .\n",
      "It -> It\n",
      "is -> be\n",
      "known -> know\n",
      "that -> that\n",
      "the -> the\n",
      "display -> display\n",
      "response -> response\n",
      "of -> of\n",
      "tubes -> tube\n",
      "is -> be\n",
      "non-linear -> non-linear\n",
      "and -> and\n",
      "is -> be\n",
      "sometimes -> sometimes\n",
      "said -> say\n",
      "to -> to\n",
      "follow -> follow\n",
      "Gamma-Law -> Gamma-Law\n",
      ". -> .\n",
      "I -> I\n",
      "am -> be\n",
      "not -> not\n",
      "certain -> certain\n",
      "if -> if\n",
      "these -> these\n",
      "non-linearities -> non-linearities\n",
      "are -> be\n",
      "`` -> ``\n",
      "Gamma-corrected -> Gamma-corrected\n",
      "'' -> ''\n",
      "before -> before\n",
      "encoding -> encode\n",
      "NTSC -> NTSC\n",
      "signals -> signal\n",
      "or -> or\n",
      "if -> if\n",
      "the -> the\n",
      "TV -> TV\n",
      "display -> display\n",
      "is -> be\n",
      "supposed -> suppose\n",
      "to -> to\n",
      "correct -> correct\n",
      "this -> this\n",
      ". -> .\n",
      "Also -> Also\n",
      ", -> ,\n",
      "if -> if\n",
      "256 -> 256\n",
      "grey -> grey\n",
      "levels -> level\n",
      ", -> ,\n",
      "for -> for\n",
      "example -> example\n",
      ", -> ,\n",
      "are -> be\n",
      "coded -> cod\n",
      "in -> in\n",
      "a -> a\n",
      "C -> C\n",
      "program -> program\n",
      "do -> do\n",
      "these -> these\n",
      "intensity -> intensity\n",
      "levels -> level\n",
      "appear -> appear\n",
      "with -> with\n",
      "linear -> linear\n",
      "brightness -> brightness\n",
      "on -> on\n",
      "a -> a\n",
      "PC -> PC\n",
      "monitor -> monitor\n",
      "? -> ?\n",
      "In -> In\n",
      "other -> other\n",
      "words -> word\n",
      "does -> do\n",
      "PC -> PC\n",
      "monitor -> monitor\n",
      "display -> display\n",
      "circuitry -> circuitry\n",
      "correct -> correct\n",
      "for -> for\n",
      "`` -> ``\n",
      "gamma -> gamma\n",
      "errrors -> errrors\n",
      "'' -> ''\n",
      "? -> ?\n",
      "Your -> Your\n",
      "response -> response\n",
      "is -> be\n",
      "much -> much\n",
      "appreciated -> appreciate\n",
      ". -> .\n",
      "Amjad -> Amjad\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "for w, pos in text_PoS_u:\n",
    "    # Map the detailed set of POS-tags to nouns/verbs for the lemmatizer\n",
    "    if pos in [\"VERB\"]:\n",
    "        pos = 'v'\n",
    "    elif pos in [\"ADJ\"]:\n",
    "        pos = 'a'\n",
    "    elif pos in [\"ADV\"]:\n",
    "        pos = 'r'\n",
    "    elif pos in [\"NOUN\"]:\n",
    "        pos = 'n'\n",
    "    else:\n",
    "        pos = 'n'\n",
    "    # print the original tokens and their lemma\n",
    "    print(f\"{w} -> {wnl.lemmatize(w, pos=pos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run - stem: run - lemma: run\n",
      "ran - stem: ran - lemma: run\n",
      "universal - stem: univers - lemma: universal\n",
      "university - stem: univers - lemma: university\n",
      "universe - stem: univers - lemma: universe\n",
      "alumnus - stem: alumnu - lemma: alumnus\n",
      "alumni - stem: alumni - lemma: alumnus\n"
     ]
    }
   ],
   "source": [
    "# To illustrate the difference:\n",
    "diff_ex = [\"run\",\"ran\",\n",
    "           \"universal\", \"university\", \"universe\",\n",
    "           \"alumnus\",\"alumni\"]\n",
    "\n",
    "for w, pos in nltk.pos_tag(diff_ex, tagset=\"universal\"):\n",
    "    # Map the detailed set of POS-tags to nouns/verbs for the lemmatizer\n",
    "    if pos in [\"VERB\"]:\n",
    "        pos = \"v\"\n",
    "    elif pos in [\"ADJ\"]:\n",
    "        pos = \"a\"\n",
    "    elif pos in [\"ADV\"]:\n",
    "        pos = \"r\"\n",
    "    elif pos in [\"NOUN\"]:\n",
    "        pos = \"n\"\n",
    "    else:\n",
    "        pos = \"n\"\n",
    "    print(f\"{w} - stem: {ps.stem(w)} - lemma: {wnl.lemmatize(w, pos=pos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfUp_mj32YHg"
   },
   "source": [
    "### 2.6. Putting it all together\n",
    "\n",
    "Let's combine all of the above techniques into a single \"tokenize + normalize\" function which will output a list of normalized words given a string of text (document) as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1662019884869,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "KzwaS4cSvr52"
   },
   "outputs": [],
   "source": [
    "# Write your custom tokenizer method here:\n",
    "def custom_tokenizer(text: str):\n",
    "    text_tokens = nltk.word_tokenize(text)\n",
    "    output = []\n",
    "    for w, pos in nltk.pos_tag(text_tokens, tagset=\"universal\"):\n",
    "        if pos in [\"VERB\"]:\n",
    "            pos = \"v\"\n",
    "        elif pos in [\"ADJ\"]:\n",
    "            pos = \"a\"\n",
    "        elif pos in [\"ADV\"]:\n",
    "            pos = \"r\"\n",
    "        elif pos in [\"NOUN\"]:\n",
    "            pos = \"n\"\n",
    "        else:\n",
    "            pos = \"n\"\n",
    "\n",
    "        # Lemmatized form accounting for POS-tag\n",
    "        l = wnl.lemmatize(w, pos=pos)\n",
    "\n",
    "        # Filter out stopwords\n",
    "        if l not in stopwords:\n",
    "            output.append(l)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1662019884870,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "m7Fet-3W3ddO",
    "outputId": "983bc229-d2e4-4066-c07a-4312ebd5a8b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi:\n",
      "\n",
      "I am digitizing a NTSC signal and displaying on a PC video monitor.\n",
      "It is known that the display response of tubes is non-linear and is\n",
      "sometimes said to follow Gamma-Law. I am not certain if these\n",
      "non-linearities are \"Gamma-corrected\" before encoding NTSC signals\n",
      "or if the TV display is supposed to correct this.\n",
      " \n",
      "Also, if  256 grey levels, for example, are coded in a C program do\n",
      "these intensity levels appear with linear brightness on a PC\n",
      "monitor? In other words does PC monitor display circuitry\n",
      "correct for \"gamma errrors\"?\n",
      " \n",
      "Your response is much appreciated.\n",
      " \n",
      "Amjad.\n",
      "----------------------\n",
      "['Hi', ':', 'I', 'digitize', 'NTSC', 'signal', 'display', 'PC', 'video', 'monitor', '.', 'It', 'know', 'display', 'response', 'tube', 'non-linear', 'sometimes', 'say', 'follow', 'Gamma-Law', '.', 'I', 'certain', 'non-linearities', '``', 'Gamma-corrected', \"''\", 'encode', 'NTSC', 'signal', 'TV', 'display', 'suppose', 'correct', '.', 'Also', ',', '256', 'grey', 'level', ',', 'example', ',', 'cod', 'C', 'program', 'intensity', 'level', 'appear', 'linear', 'brightness', 'PC', 'monitor', '?', 'In', 'word', 'PC', 'monitor', 'display', 'circuitry', 'correct', '``', 'gamma', 'errrors', \"''\", '?', 'Your', 'response', 'much', 'appreciate', '.', 'Amjad', '.']\n"
     ]
    }
   ],
   "source": [
    "# Try it out on the text\n",
    "print(text)\n",
    "print('----------------------')\n",
    "print(custom_tokenizer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfxFjHPM3jrQ"
   },
   "source": [
    "# 3. Word embeddings and text classification\n",
    "\n",
    "Using the NLP normalization techniques from above, including our custom tokenization method, we want to train a simple multi-class ML classifier to predict the news topic. In order to do so, we must first vectorize the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNIGZbIM32VC"
   },
   "source": [
    "### 3.1. Bag-of-words (BOW)\n",
    "\n",
    "Bag-of-words is the simplest *embedding* technique in which words are represented as one-hot encoded numeric vectors of word counts. The length of these vectors corresponds to the size of the (reduced) vocabulary of the training corpus.\n",
    "That is, each column $j$ in the resulting sparse matrix represents a word and and each row $i$ represents a different observation (i.e. document), and the coresonping entry in the matrix is the word count of how many times the word $j$ appears in document $i$.\n",
    "See [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) for the scikit-learn implementation of the bag-of-words embedding and its many options.\n",
    "\n",
    "We start by training the bag-of-words on our train corpus, and compare the vocabulary size with and without our `'custom_tokenizer'` normalization procedure. We can ignore tokens that appear in less than 0.1% of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_vectorizer = CountVectorizer(lowercase=True, min_df=1e-3)\n",
    "\n",
    "bow_train_simple = simple_vectorizer.fit_transform(df_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train_simple[11, 285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 9187)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train_simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 174431,
     "status": "ok",
     "timestamp": 1662020059298,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "v5A-Xfxl6wYb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pascheo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=custom_tokenizer, lowercase=True, min_df=1e-3)\n",
    "\n",
    "bow_train = vectorizer.fit_transform(df_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 7230)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ss1gb3fi9svt"
   },
   "source": [
    "### 3.2. Bag-of-words (BOW) with Term-frequency Inverse-document-frequency (TF-IDF)\n",
    "\n",
    "TF-IDF uses the **same** one-hot encoding as traditional BOW, but transforms the simple counts to the relative word frequency, normalized by the inverse-document-frequency to account for frequently occurring words across all documents. \n",
    "\n",
    "The intuition is that not only the word's frequency in a given document indicates if that word represents the document well, but also how rare it is in other documents in comparison.\n",
    "\n",
    "We now compute the TF-IDF transformation of the BoW, using our `'custom_tokenizer'`. See the [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and [TfidfTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html) scikit-learn classes for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Way 1: two-step bag of words and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "#using the BoW from above:\n",
    "tfidf_train0 = tfidf_transformer.fit_transform(bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 7230)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Way 2: both at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we repeat the two steps above in a single equivalent step, using TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, lowercase=True, min_df=1e-3)\n",
    "\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(df_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 7230)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Topic Classification using Simple Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Lemmatization and TF-IDF impacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we want to study the impact of lemmatization and of TF-IDF on the classification accuracy of a simple ML model. We use a multi-class logistic regression with arbitrary hyper-parameter `C=10`. Choose the `'liblinear'` solver, that seems more efficient for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the test accuracy using BoW without lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1662020167450,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "k5fRMDy-XTZA",
    "outputId": "797ea1f6-ba41-482f-e3a1-18f10ab828dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pascheo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=10, max_iter=int(1e4), solver='liblinear')\n",
    "clf.fit(bow_train_simple, df_train[\"class\"])\n",
    "\n",
    "# Run the inference on test data\n",
    "pred_bow_simple = clf.predict(simple_vectorizer.transform(df_test['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bow_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1662020167450,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "k5fRMDy-XTZA",
    "outputId": "797ea1f6-ba41-482f-e3a1-18f10ab828dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7543275632490013"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report the score\n",
    "accuracy_score(df_test[\"class\"], pred_bow_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the lemmatization improving the test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1662020167450,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "k5fRMDy-XTZA",
    "outputId": "797ea1f6-ba41-482f-e3a1-18f10ab828dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pascheo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=10, max_iter=int(1e4), solver='liblinear')\n",
    "clf.fit(bow_train, df_train[\"class\"])\n",
    "\n",
    "# Run the inference on test data\n",
    "pred_bow = clf.predict(vectorizer.transform(df_test[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1662020167450,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "k5fRMDy-XTZA",
    "outputId": "797ea1f6-ba41-482f-e3a1-18f10ab828dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7603195739014648"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report the score\n",
    "accuracy_score(df_test[\"class\"], pred_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oQxaBxksixp"
   },
   "source": [
    "Let's see if using TF-IDF weights improves the score further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1662020451269,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "ABuLdR_KtNMB",
    "outputId": "b149ebfd-8841-4d8f-af90-a14646920f97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pascheo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=10, max_iter=int(1e4), solver='liblinear')\n",
    "clf.fit(tfidf_train, df_train[\"class\"])\n",
    "\n",
    "# Run the inference on test data\n",
    "pred_tfidf = clf.predict(tfidf_vectorizer.transform(df_test[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1662020451269,
     "user": {
      "displayName": "Olivier Pasche"
     },
     "user_tz": -120
    },
    "id": "ABuLdR_KtNMB",
    "outputId": "b149ebfd-8841-4d8f-af90-a14646920f97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135818908122503"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report the score\n",
    "accuracy_score(df_test[\"class\"], pred_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrNaJO09u4zR"
   },
   "source": [
    "This already performs better than a simple BOW model. You can try changing the vectorizer parameters or using a different ML model for the classification. We will investigate more advanced methods in later labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a cross-validated grid search to select the best hyper-parameter values for both the TF-IDF vectorizer and the logistic regression model at the same time using a sklearn `Pipeline`. For the TF-IDF Vectorizer, let's for example check if considering bigrams in the vocabulary helps the classifier. For the logistic regression, the tuning parameter is the cost ($1/penalty$) `'C'`. (Non exhaustive; there are other parameters of the vectorizer that might be worth fine-tuning, for example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(tokenizer=custom_tokenizer, lowercase=True, min_df=1e-3, max_df=0.999)),\n",
    "    (\"logistic\", LogisticRegression(max_iter=int(1e4), solver='liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pascheo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(max_df=0.999,\n",
       "                                                        min_df=0.001,\n",
       "                                                        tokenizer=&lt;function custom_tokenizer at 0x0000023D97D6DD00&gt;)),\n",
       "                                       (&#x27;logistic&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000,\n",
       "                                                           solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={&#x27;logistic__C&#x27;: [5, 10, 50, 100],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2)]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(max_df=0.999,\n",
       "                                                        min_df=0.001,\n",
       "                                                        tokenizer=&lt;function custom_tokenizer at 0x0000023D97D6DD00&gt;)),\n",
       "                                       (&#x27;logistic&#x27;,\n",
       "                                        LogisticRegression(max_iter=10000,\n",
       "                                                           solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={&#x27;logistic__C&#x27;: [5, 10, 50, 100],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2)]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.999, min_df=0.001,\n",
       "                                 tokenizer=&lt;function custom_tokenizer at 0x0000023D97D6DD00&gt;)),\n",
       "                (&#x27;logistic&#x27;,\n",
       "                 LogisticRegression(C=50, max_iter=10000, solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_df=0.999, min_df=0.001,\n",
       "                tokenizer=&lt;function custom_tokenizer at 0x0000023D97D6DD00&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=50, max_iter=10000, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(max_df=0.999,\n",
       "                                                        min_df=0.001,\n",
       "                                                        tokenizer=<function custom_tokenizer at 0x0000023D97D6DD00>)),\n",
       "                                       ('logistic',\n",
       "                                        LogisticRegression(max_iter=10000,\n",
       "                                                           solver='liblinear'))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={'logistic__C': [5, 10, 50, 100],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "my_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    \"logistic__C\": [5, 10, 50, 100],\n",
    "}\n",
    "\n",
    "# Define folds\n",
    "folds = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define grid search CV\n",
    "tfidf_logistic_cv = GridSearchCV(estimator=logistic_pipe, param_grid=my_grid, scoring=\"accuracy\", cv=folds, n_jobs=-2)\n",
    "\n",
    "# Run CV\n",
    "tfidf_logistic_cv.fit(df_train[\"text\"], df_train[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logistic__C</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.756205</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>9.341191</td>\n",
       "      <td>0.432363</td>\n",
       "      <td>50</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'logistic__C': 50, 'tfidf__ngram_range': (1, 1)}</td>\n",
       "      <td>0.867198</td>\n",
       "      <td>0.859043</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.860874</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.950673</td>\n",
       "      <td>0.444223</td>\n",
       "      <td>9.520119</td>\n",
       "      <td>0.705955</td>\n",
       "      <td>50</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'logistic__C': 50, 'tfidf__ngram_range': (1, 2)}</td>\n",
       "      <td>0.876494</td>\n",
       "      <td>0.848404</td>\n",
       "      <td>0.848404</td>\n",
       "      <td>0.857768</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.857976</td>\n",
       "      <td>0.313011</td>\n",
       "      <td>8.450177</td>\n",
       "      <td>0.470445</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'logistic__C': 10, 'tfidf__ngram_range': (1, 1)}</td>\n",
       "      <td>0.859230</td>\n",
       "      <td>0.859043</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.856445</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.714240</td>\n",
       "      <td>0.739358</td>\n",
       "      <td>9.147296</td>\n",
       "      <td>0.508849</td>\n",
       "      <td>100</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'logistic__C': 100, 'tfidf__ngram_range': (1,...</td>\n",
       "      <td>0.863214</td>\n",
       "      <td>0.853723</td>\n",
       "      <td>0.849734</td>\n",
       "      <td>0.855557</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.248445</td>\n",
       "      <td>4.250944</td>\n",
       "      <td>6.377897</td>\n",
       "      <td>2.155197</td>\n",
       "      <td>100</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'logistic__C': 100, 'tfidf__ngram_range': (1,...</td>\n",
       "      <td>0.873838</td>\n",
       "      <td>0.849734</td>\n",
       "      <td>0.843085</td>\n",
       "      <td>0.855552</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.680199</td>\n",
       "      <td>0.548145</td>\n",
       "      <td>8.306638</td>\n",
       "      <td>0.355143</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'logistic__C': 5, 'tfidf__ngram_range': (1, 1)}</td>\n",
       "      <td>0.856574</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.847074</td>\n",
       "      <td>0.851571</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.947836</td>\n",
       "      <td>0.870978</td>\n",
       "      <td>9.006927</td>\n",
       "      <td>0.923308</td>\n",
       "      <td>10</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'logistic__C': 10, 'tfidf__ngram_range': (1, 2)}</td>\n",
       "      <td>0.864542</td>\n",
       "      <td>0.848404</td>\n",
       "      <td>0.839096</td>\n",
       "      <td>0.850681</td>\n",
       "      <td>0.010512</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.429785</td>\n",
       "      <td>0.560696</td>\n",
       "      <td>8.577892</td>\n",
       "      <td>0.423756</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'logistic__C': 5, 'tfidf__ngram_range': (1, 2)}</td>\n",
       "      <td>0.855246</td>\n",
       "      <td>0.845745</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.843593</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4      19.756205      0.491919         9.341191        0.432363   \n",
       "5      19.950673      0.444223         9.520119        0.705955   \n",
       "2      20.857976      0.313011         8.450177        0.470445   \n",
       "6      19.714240      0.739358         9.147296        0.508849   \n",
       "7      14.248445      4.250944         6.377897        2.155197   \n",
       "0      20.680199      0.548145         8.306638        0.355143   \n",
       "3      20.947836      0.870978         9.006927        0.923308   \n",
       "1      21.429785      0.560696         8.577892        0.423756   \n",
       "\n",
       "   param_logistic__C param_tfidf__ngram_range  \\\n",
       "4                 50                   (1, 1)   \n",
       "5                 50                   (1, 2)   \n",
       "2                 10                   (1, 1)   \n",
       "6                100                   (1, 1)   \n",
       "7                100                   (1, 2)   \n",
       "0                  5                   (1, 1)   \n",
       "3                 10                   (1, 2)   \n",
       "1                  5                   (1, 2)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "4  {'logistic__C': 50, 'tfidf__ngram_range': (1, 1)}           0.867198   \n",
       "5  {'logistic__C': 50, 'tfidf__ngram_range': (1, 2)}           0.876494   \n",
       "2  {'logistic__C': 10, 'tfidf__ngram_range': (1, 1)}           0.859230   \n",
       "6  {'logistic__C': 100, 'tfidf__ngram_range': (1,...           0.863214   \n",
       "7  {'logistic__C': 100, 'tfidf__ngram_range': (1,...           0.873838   \n",
       "0   {'logistic__C': 5, 'tfidf__ngram_range': (1, 1)}           0.856574   \n",
       "3  {'logistic__C': 10, 'tfidf__ngram_range': (1, 2)}           0.864542   \n",
       "1   {'logistic__C': 5, 'tfidf__ngram_range': (1, 2)}           0.855246   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "4           0.859043           0.856383         0.860874        0.004601   \n",
       "5           0.848404           0.848404         0.857768        0.013242   \n",
       "2           0.859043           0.851064         0.856445        0.003806   \n",
       "6           0.853723           0.849734         0.855557        0.005654   \n",
       "7           0.849734           0.843085         0.855552        0.013212   \n",
       "0           0.851064           0.847074         0.851571        0.003895   \n",
       "3           0.848404           0.839096         0.850681        0.010512   \n",
       "1           0.845745           0.829787         0.843593        0.010504   \n",
       "\n",
       "   rank_test_score  \n",
       "4                1  \n",
       "5                2  \n",
       "2                3  \n",
       "6                4  \n",
       "7                5  \n",
       "0                6  \n",
       "3                7  \n",
       "1                8  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_logistic_cv.cv_results_).sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic__C': 50, 'tfidf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_logistic_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pascheo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8095872170439414"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tfidf_logistic_cv.best_estimator_\n",
    "y_hat = best_model.predict(df_test[\"text\"])\n",
    "accuracy_score(df_test[\"class\"], y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run some classification accuracy diagnostics to understand in more detail how our model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(df_test[\"class\"], y_hat)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data_test.target_names).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rows = actual category  \n",
    "columns = predicted category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.72      0.65      0.68       319\n",
      "         comp.graphics       0.88      0.89      0.89       389\n",
      "               sci.med       0.82      0.87      0.84       396\n",
      "soc.religion.christian       0.80      0.80      0.80       398\n",
      "\n",
      "              accuracy                           0.81      1502\n",
      "             macro avg       0.80      0.80      0.80      1502\n",
      "          weighted avg       0.81      0.81      0.81      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test[\"class\"], y_hat, target_names=data_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- precision = $TP/(TP+FP)$ = When the model is predicting this class, how often it is right\n",
    "- recall = $TP/(TP+FN)$ = How well the model is performing (accuracy) within each (true) class\n",
    "- F1 = harmonic mean of precision and recall = $\\frac{2}{(1/precision)+(1/recall)}$ (1= best, prefect precision and recall, 0=worst, either precision or recall is zero)\n",
    "- support = number of occurences in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the topic of a few sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lungs and heart health => sci.med\n",
      "CPU or GPU? => comp.graphics\n",
      "God and faith => soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['Lungs and heart health', \"CPU or GPU?\", 'God and faith']\n",
    "\n",
    "predicted = best_model.predict(docs_new)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print(doc, \"=>\", data_test.target_names[category])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Text wrangling and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, textual datasets are rarely clean nor well structured, and often need some wrangling and preprocessing to be used effectively. \n",
    "\n",
    "Furthermore, depending on the specific task and context at hand, there are often other tailor-made transformations that can prove usefull as an addition or a replacement to normalization. (E.g. the way you would like to handle the `@`symbol might differ between e-mail and social media data. Or there might be specific groups of words that have similar meaning in general, but whose differentiation is important in a specific context.)\n",
    "\n",
    "Additionally to processing and normalizing the test for vectorisation, manual feature extraction can also prove useful. For example the number of exclamation marks, the number of ALL CAPS WORDS, or the average word per sentence ratio might give additional information on the tone or sentiment of written text, depending on the context and model.\n",
    "\n",
    "Here are a few basic string methods that can come in handy for those scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there!'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hi there!\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there!'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.replace(\"Hi\",\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there ! '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.replace(\"!\",\" ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi thr!'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.replace(\"e\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'there!']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi there!'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `string.punctuation` only contains the ASCII punctuation.  \n",
    "There are non-ASCII Unicode punctuation characters (e.g. different types of apostrophes and quotes, like `` , , ` ``). One typically replaces them by the corresponding ` ' ` or ` \" ` at the data-cleaning stage, before potential normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The few examples above are just to inspire you some ideas. There are many things you could think of to analyze and extract informative summaries from text data. The pandas `<pd.Series>.apply()` method can come in very handy with custom user-defined functions.\n",
    "\n",
    "pd.Series also has a `str` subset of methods for text data. Here are a few dummy examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi there!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My dog is cute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i lost my wallet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            my_text\n",
       "0         Hi there!\n",
       "1   My dog is cute.\n",
       "2  i lost my wallet"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "str_text = pd.DataFrame({\"my_text\":[\"Hi there!\",\"My dog is cute.\",\"i lost my wallet\"]})\n",
    "str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Hi there!\n",
       "1     My dog is cute.\n",
       "2    I lost my wallet\n",
       "Name: my_text, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_text.my_text.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           hi there!\n",
       "1     my dog is cute.\n",
       "2    i lost my wallet\n",
       "Name: my_text, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_text.my_text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "Name: my_text, dtype: bool"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_text.my_text.str.contains(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "Name: my_text, dtype: bool"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_text.my_text.str.contains(\"my\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    1\n",
       "Name: my_text, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_text.my_text.str.count(\"e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Hi thr!\n",
       "1     My dog is cut.\n",
       "2    i lost my wallt\n",
       "Name: my_text, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_text.my_text.str.replace(\"e\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many more examples in the pandas documentation.\n",
    "\n",
    "For more complicated text processing procedures, one would usually turn to [**regular expressions**](https://en.wikipedia.org/wiki/Regular_expression), as a much more powerful tool. The [`re` module](https://docs.python.org/3/library/re.html) provides the base tools to work with regular expressions in python. Some `pandas`'s  `Series.str` methods above also accept regular expressions.\n",
    "\n",
    "This goes beyond the scope of this seminar, but if you are interested:\n",
    "- [Interactive RegEx tutorials](https://regexr.com/)\n",
    "- [Another tutorial](https://www.w3schools.com/python/python_regex.asp)\n",
    "- And many more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'Luis']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re_str = \"Hello, how are you Luis?\"\n",
    "re.findall(r\"[A-Z]\\w+\", re_str)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNCtguPGtWiKfucgbeYKTic",
   "collapsed_sections": [
    "yv7hitczyvUA",
    "VfzsMmdIymLR",
    "IJnX396HzwRM",
    "7byMSxD0yq0O",
    "TfUp_mj32YHg",
    "oNIGZbIM32VC",
    "ss1gb3fi9svt"
   ],
   "name": "Lab1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
